# -*- coding: utf-8 -*-
"""IR_Lab_1

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1QfBo39MNO2MlYTiAlEryYfLSHqQcvcAa
"""

# Define the given documents
documents = [
    "THE QUICK BROWN FOX JUMPS OVER THE LAZY DOG.",
    "THE LAZY DOG LIES IN THE SUN.",
    "A FOX IS QUICK AND CLEVER Learning running.",
    "SUNSHINE MAKES THE FOX HAPPY."
]

# Convert documents to lowercase
documents = [doc.lower() for doc in documents]
print("Cleaned Documents:", documents)

import nltk
from nltk.corpus import stopwords
import re

nltk.download('stopwords')
stop_words = set(stopwords.words('english'))

# Remove punctuation and stop words
def remove_stopwords(text):
    text = re.sub(r'[^\w\s]', '', text)  # Remove punctuation
    return ' '.join([word for word in text.split() if word not in stop_words])

processed_docs = [remove_stopwords(doc) for doc in documents]
print("After Stop Word Removal:", processed_docs)

import nltk
nltk.download('punkt_tab')
from nltk.tokenize import word_tokenize
nltk.download('punkt')

tokenized_docs = [word_tokenize(doc) for doc in processed_docs]
print("Tokenized Documents:", tokenized_docs)

from nltk.stem import PorterStemmer

stemmer = PorterStemmer()

stemmed_docs = [[stemmer.stem(word) for word in doc] for doc in tokenized_docs]
print("After Stemming:", stemmed_docs)

from nltk.stem import WordNetLemmatizer
nltk.download('wordnet')

lemmatizer = WordNetLemmatizer()

lemmatized_docs = [[lemmatizer.lemmatize(word) for word in doc] for doc in tokenized_docs]
print("After Lemmatization:", lemmatized_docs)

from collections import defaultdict

inverted_index = defaultdict(list)

for doc_id, doc in enumerate(lemmatized_docs, start=1):
    for term in doc:
        if doc_id not in inverted_index[term]:
            inverted_index[term].append(doc_id)

print("Inverted Index:", dict(inverted_index))

def boolean_query(query, index):
    query = query.lower().split()

    if len(query) < 3:
        return "Invalid query format. Use format like 'term1 AND term2'"

    result_set = set(index[query[0]]) if query[0] in index else set()

    i = 1
    while i < len(query) - 1:  # Ensure we don't go out of range
        operator = query[i]
        term = query[i + 1]

        if term not in index:
            term_set = set()
        else:
            term_set = set(index[term])

        if operator == "and":
            result_set &= term_set
        elif operator == "or":
            result_set |= term_set
        elif operator == "not":
            result_set -= term_set

        i += 2  # Move to the next operator

    return result_set

# Run the queries again
print("Query Result (fox AND quick):", boolean_query("fox and quick", inverted_index))
print("Query Result (lazy OR happy):", boolean_query("lazy or happy", inverted_index))
print("Query Result (dog AND NOT sunshine):", boolean_query("dog and not sunshine", inverted_index))